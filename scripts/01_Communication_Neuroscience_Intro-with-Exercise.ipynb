{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Univariate analysis of block design, one condition versus rest, single subject\n",
    "==============================================================================\n",
    "\n",
    "Authors: Bertrand Thirion, Elvis Dohmatob , Christophe Pallier, 2015--2017\n",
    "\n",
    "Modified: Ralf Schmaelzle, 2019\n",
    "\n",
    "In this tutorial, we compare the fMRI signal during periods of auditory stimulation\n",
    "versus periods of rest, using a General Linear Model (GLM). We will\n",
    "use a univariate approach in which independent tests are performed at\n",
    "each single-voxel.\n",
    "\n",
    "The dataset comes from experiment conducted at the FIL by Geriant Rees\n",
    "under the direction of Karl Friston. It is provided by FIL methods\n",
    "group which develops the SPM software.\n",
    "\n",
    "According to SPM documentation, 96 acquisitions were made (RT=7s), in\n",
    "blocks of 6, giving 16 42s blocks. The condition for successive blocks\n",
    "alternated between rest and auditory stimulation, starting with rest.\n",
    "Auditory stimulation was bi-syllabic words presented binaurally at a\n",
    "rate of 60 per minute. The functional data starts at acquisiton 4,\n",
    "image fM00223_004.\n",
    "\n",
    "The whole brain BOLD/EPI images were acquired on a modified 2T Siemens\n",
    "MAGNETOM Vision system. Each acquisition consisted of 64 contiguous\n",
    "slices (64x64x64 3mm x 3mm x 3mm voxels). Acquisition took 6.05s, with\n",
    "the scan to scan repeat time (RT) set arbitrarily to 7s.\n",
    "\n",
    "\n",
    "This analyse described here is performed in the native space, on the\n",
    "original EPI scans without any spatial or temporal preprocessing.\n",
    "(More sensitive results would likely be obtained on the corrected,\n",
    "spatially normalized and smoothed images).\n",
    "\n",
    "\n",
    "How does this \"jupyter-thing\" work? \n",
    "\n",
    "It is very easy. A notebook basically consists of cells that can be of two main kinds: Code cells and comment cells. The one you are reading is a comment cell, the one-line-cell below (\"Import modules\") as well, then comes a code cell. The idea behind this is called literate programming, that is the comment-cells explain stuff in natural language, and the code cells exectute some computer code (and can also display output).\n",
    "\n",
    "How do I get ahead?\n",
    "\n",
    "To click through cells, you can either click the 'Run' button above, or you can click in to a cell and press (SHIFT + ENTER). Try it now, and then go...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, nibabel\n",
    "!pip install nistats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import seaborn as sns\n",
    "\n",
    "from nilearn import plotting, datasets, image     \n",
    "from nilearn.image import concat_imgs\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "from nistats.first_level_model import FirstLevelModel\n",
    "from nistats.datasets import fetch_spm_auditory\n",
    "from nistats.reporting import plot_design_matrix\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img\n",
    "\n",
    "from nibabel.affines import apply_affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have made it until here, you will see some confusing code about requirements or so that you can safely ignore. Just go ahead by shift-enter-clicking or pressing the run-button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the data\n",
    "-------------------\n",
    "\n",
    "The next line of code will fetch a whole fMRI dataset from a server into our litte \"data-oven\" (the Binder platform runs a virtual machine that runs this jupyter notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data = fetch_spm_auditory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the filenames of the functional images by just entering the name of the data-structure that holds the fetched data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are a ton of files. Specifically, we downloaded functional files (from the fMRI experiment), one structural file (a high-res image of the person's brain), and some events (with info what was presented when).\n",
    "\n",
    "Display the first functional image:\n",
    "There will be some ugly red error code. Just re-run the cell again and it should be gone!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_img(subject_data.func[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "in the next cell, please change the code so you display another than the first (in python this is counted as 0-th) image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(subject_data.func[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also display the subject's anatomical image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anat(subject_data.anat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we concatenate all the \"3D EPI images\" (i.e. the functionals) into a single 4D image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_img = concat_imgs(subject_data.func)\n",
    "print(fmri_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "What does this output of the above cell actually mean? Explain to yourself by drawing and to your neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data from one voxel, that is retrieve the over-time activity series from one spot of the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_one_voxel = fmri_img.get_data()[22,30,26,:] #22,30,26\n",
    "plt.figure(figsize = (10,2))\n",
    "plt.plot(data_from_one_voxel);\n",
    "plt.xlabel('Time (volumes)');\n",
    "plt.ylabel('fMRI Signal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "Next, please try to insert a new empty cell below (so you also learn how to edit this notebook) \n",
    "Once you have successfully done that, copy the code for displaying one voxel's data into the new cell and play around by changing the voxel-coordinates. Try this multiple times. Can you find a particular wild voxel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show you how we can do math with these data, we can, for instance, average all the EPI images into one in order to create a background image that will be used to display the activations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_img = image.mean_img(fmri_img)\n",
    "plot_anat(mean_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the experimental paradigm\n",
    "------------------------------------\n",
    "\n",
    "Our goal is to actually analyze this single-person experiment (auditory stimuluation).\n",
    "\n",
    "***Exercise:*** What do you expect to find? \n",
    "\n",
    "For the actual analysis, we must provide a description of the experiment, that is, define the timing of the auditory stimulation and rest periods. According to the documentation of the dataset, there were 16 42s blocks --- in\n",
    "which 6 scans were acquired --- alternating between rest and auditory stimulation, starting with rest. We use standard python functions to create a pandas.DataFrame object that specifies the timings:\n",
    "\n",
    "(you don't need to understand the details of this yet - just execute the code and try to get the gist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 7.\n",
    "slice_time_ref = 0.\n",
    "n_scans = 96\n",
    "epoch_duration = 6 * tr  # duration in seconds\n",
    "conditions = ['rest', 'active'] * 8\n",
    "n_blocks = len(conditions)\n",
    "duration = epoch_duration * np.ones(n_blocks)\n",
    "onset = np.linspace(0, (n_blocks - 1) * epoch_duration, n_blocks)\n",
    "\n",
    "events = pd.DataFrame({'onset': onset, 'duration': duration, 'trial_type': conditions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``events`` object contains the information for the design:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** What kind of design are we dealing with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the GLM analysis\n",
    "---------------------------\n",
    "\n",
    "We need to construct a *design matrix* using the timing information provided by the ``events`` object. The design matrix contains regressors of interest as well as regressors of non-interest modeling temporal drifts. \n",
    "\n",
    "With all these ingredients, we then create a ``FirstLevelModel`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_times = np.linspace(0, (n_scans - 1) * tr, n_scans)\n",
    "drift_model = 'Cosine'\n",
    "period_cut = 4. * epoch_duration\n",
    "hrf_model = 'glover + derivative'\n",
    "fmri_glm = FirstLevelModel(tr, slice_time_ref, noise_model='ar1',\n",
    "                           standardize=False, hrf_model=hrf_model,\n",
    "                           drift_model=drift_model)# period_cut=period_cut) #not nice, but didn't work otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drumroll: Now, we fit the FirstLevelModel 'fmri_glm' to the data (4D dataset). Note that this is also called a mass-univariate analysis, that is we fit this model for each voxel individually, getting a beta-coefficient for each voxel. This is also why it takes a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm = fmri_glm.fit(fmri_img, events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can inspect the design matrix (rows represent time, and\n",
    "columns contain the predictors):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix = fmri_glm.design_matrices_[0]\n",
    "fig, ax1 = plt.subplots(figsize=(6, 8), nrows=1, ncols=1)\n",
    "plot_design_matrix(design_matrix, ax= ax1, rescale= True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** What does this matrix exactly mean? What are the critical columns that we care about in order to test our hypothesis? Hey, speaking of this, what's our hypthesis, actually? Explain to your neighbor or create new cell (change it so it is a comment cell) and write the answer in (it's better to be explicit about the hypothesis)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column contains the expected reponse profile of regions which are\n",
    "sensitive to the auditory stimulation. Let's grab that from the design matrix and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(design_matrix['active'])\n",
    "plt.xlabel('scan')\n",
    "plt.title('Expected Auditory Response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** Bonus question: Why is this expected timecourse so oddly shaped and not just a on-off-pattern?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting voxels with significant effects\n",
    "-----------------------------------------\n",
    "\n",
    "To access the estimated coefficients (Betas of the GLM model), we created constrasts with a single '1' in each of the columns.\n",
    "\n",
    "(Again, you don't have to understand the details of the code, just try to follow the overall gist for now)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "contrasts = dict([(column, contrast_matrix[i])\n",
    "                  for i, column in enumerate(design_matrix.columns)])\n",
    "\n",
    "\"\"\"\n",
    "contrasts::\n",
    "\n",
    "  {\n",
    "  'active':            array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'active_derivative': array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'constant':          array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
    "  'drift_1':           array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_2':           array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_3':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_4':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_5':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]),\n",
    "  'drift_6':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
    "  'drift_7':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n",
    "  'rest':              array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'rest_derivative':   array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compare the two conditions 'active' and 'rest' by\n",
    "generating the relevant contrast that we can use to ~~ isolate ~~ the psychological process\n",
    "\n",
    "(there are some tricky problems with this notion of process isolation and we're glossing over a lot of detail here, but for our purpose to localize brain regions associated with sound-stimulation this isn't so critical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_minus_rest =  contrasts['active'] - contrasts['rest']\n",
    "\n",
    "eff_map = fmri_glm.compute_contrast(active_minus_rest,\n",
    "                                    output_type='effect_size')\n",
    "\n",
    "z_map = fmri_glm.compute_contrast(active_minus_rest,\n",
    "                                  output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot thresholded z scores map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(z_map, bg_img=mean_img, threshold=3.0,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Active minus Rest (Z>3)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** Tada, what do you see? Where in the brain are we? What do you know about this territory? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** Below, you can also get a cooler view that you can surf in 3D. Try to do that and find whether there are other hotspots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_img(z_map, bg_img=mean_img, threshold=3., title=\"Active vs. Rest contrast\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ``nibabel.save`` to save the effect and zscore maps to the disk (Unfortunately, since we're running this in the cloud, you cannot get the data, but you could download the notebook, run the same code on your computer, and then you have it forever). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'results'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "nibabel.save(z_map, join('results', 'active_vs_rest_z_map.nii'))\n",
    "nibabel.save(eff_map, join('results', 'active_vs_rest_eff_map.nii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the signal from a voxels\n",
    " --------------------------------\n",
    "\n",
    "We search for the voxel with the larger z-score and plot the signal\n",
    "(warning: double dipping!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the coordinates of the peak\n",
    "values = z_map.get_fdata()\n",
    "coord_peaks = np.dstack(np.unravel_index(np.argsort(values.ravel()),\n",
    "                                         values.shape))[0, 0, :]\n",
    "coord_mm = apply_affine(z_map.affine, coord_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a masker for the voxel (allowing us to detrend the signal) and extract the time course.\n",
    "\n",
    "(Again, no details needed here - we're just using a tool to extract from the large 4d-dataset the activity in a region around where we found something - this will then be put into the variable 'sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = NiftiSpheresMasker([coord_mm], radius=3,\n",
    "                          detrend=True, standardize=True,\n",
    "                          high_pass=None, low_pass=None, t_r=7.)\n",
    "sig = mask.fit_transform(fmri_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** Create a new cell below, enter 'sig' and press enter. What does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the signal and the theoretical response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frame_times, sig, label='voxel %d %d %d' % tuple(coord_mm))\n",
    "plt.plot(design_matrix['active'], color='red', label='model')\n",
    "plt.xlabel('scan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** What do you see? What does it mean? Why isn't the result perfect?\n",
    "\n",
    "***Exercise:*** Congratulations, you have just completed a first analysis. Try to lean back and think about the steps you did! \n",
    "What would be the next steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
