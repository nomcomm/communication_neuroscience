{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Univariate analysis of block design, one condition versus rest, single subject\n",
    "==============================================================================\n",
    "\n",
    "Authors: Bertrand Thirion, Elvis Dohmatob , Christophe Pallier, 2015--2017\n",
    "Modified: Ralf Schmaelzle, 2019\n",
    "\n",
    "In this tutorial, we compare the fMRI signal during periods of auditory stimulation\n",
    "versus periods of rest, using a General Linear Model (GLM). We will\n",
    "use a univariate approach in which independent tests are performed at\n",
    "each single-voxel.\n",
    "\n",
    "The dataset comes from experiment conducted at the FIL by Geriant Rees\n",
    "under the direction of Karl Friston. It is provided by FIL methods\n",
    "group which develops the SPM software.\n",
    "\n",
    "According to SPM documentation, 96 acquisitions were made (RT=7s), in\n",
    "blocks of 6, giving 16 42s blocks. The condition for successive blocks\n",
    "alternated between rest and auditory stimulation, starting with rest.\n",
    "Auditory stimulation was bi-syllabic words presented binaurally at a\n",
    "rate of 60 per minute. The functional data starts at acquisiton 4,\n",
    "image fM00223_004.\n",
    "\n",
    "The whole brain BOLD/EPI images were acquired on a modified 2T Siemens\n",
    "MAGNETOM Vision system. Each acquisition consisted of 64 contiguous\n",
    "slices (64x64x64 3mm x 3mm x 3mm voxels). Acquisition took 6.05s, with\n",
    "the scan to scan repeat time (RT) set arbitrarily to 7s.\n",
    "\n",
    "\n",
    "This analyse described here is performed in the native space, on the\n",
    "original EPI scans without any spatial or temporal preprocessing.\n",
    "(More sensitive results would likely be obtained on the corrected,\n",
    "spatially normalized and smoothed images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, nibabel\n",
    "!pip install nistats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import seaborn as sns\n",
    "\n",
    "from nilearn import plotting, datasets, image     \n",
    "from nilearn.image import concat_imgs\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "from nistats.first_level_model import FirstLevelModel\n",
    "from nistats.datasets import fetch_spm_auditory\n",
    "from nistats.reporting import plot_design_matrix\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img\n",
    "\n",
    "from nibabel.affines import apply_affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the data\n",
    "-------------------\n",
    "\n",
    "We can list the filenames of the functional images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data = fetch_spm_auditory()\n",
    "subject_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first functional image:\n",
    "\n",
    "RalfNote: there will be some ugly red error code. Just re-run the cell again and it should be gone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_img(subject_data.func[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the subject's anatomical image:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anat(subject_data.anat);\n",
    "#plotting.view_img(subject_data.anat)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we concatenate all the 3D EPI image into a single 4D image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_img = concat_imgs(subject_data.func)\n",
    "print(fmri_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot data from one voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_one_voxel = fmri_img.get_data()[22,30,26,:] #22,30,26\n",
    "plt.figure(figsize = (10,2))\n",
    "plt.plot(data_from_one_voxel);\n",
    "plt.xlabel('Time (volumes)');\n",
    "plt.ylabel('fMRI Signal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we average all the EPI images in order to create a background image that will be used to display the activations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_img = image.mean_img(fmri_img)\n",
    "plot_anat(mean_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the experimental paradigm\n",
    "------------------------------------\n",
    "\n",
    "We must provide a description of the experiment, that is, define the\n",
    "timing of the auditory stimulation and rest periods. According to\n",
    "the documentation of the dataset, there were 16 42s blocks --- in\n",
    "which 6 scans were acquired --- alternating between rest and\n",
    "auditory stimulation, starting with rest. We use standard python\n",
    "functions to create a pandas.DataFrame object that specifies the\n",
    "timings:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 7.\n",
    "slice_time_ref = 0.\n",
    "n_scans = 96\n",
    "epoch_duration = 6 * tr  # duration in seconds\n",
    "conditions = ['rest', 'active'] * 8\n",
    "n_blocks = len(conditions)\n",
    "duration = epoch_duration * np.ones(n_blocks)\n",
    "onset = np.linspace(0, (n_blocks - 1) * epoch_duration, n_blocks)\n",
    "\n",
    "events = pd.DataFrame({'onset': onset, 'duration': duration, 'trial_type': conditions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``events`` object contains the information for the design:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the GLM analysis\n",
    "---------------------------\n",
    "\n",
    "We need to construct a *design matrix* using the timing information\n",
    "provided by the ``events`` object. The design matrix contains\n",
    "regressors of interest as well as regressors of non-interest\n",
    "modeling temporal drifts:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_times = np.linspace(0, (n_scans - 1) * tr, n_scans)\n",
    "drift_model = 'Cosine'\n",
    "period_cut = 4. * epoch_duration\n",
    "hrf_model = 'glover + derivative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to create a ``FirstLevelModel`` object\n",
    "and fit it to the 4D dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm = FirstLevelModel(tr, slice_time_ref, noise_model='ar1',\n",
    "                           standardize=False, hrf_model=hrf_model,\n",
    "                           drift_model=drift_model, period_cut=period_cut)\n",
    "fmri_glm = fmri_glm.fit(fmri_img, events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can inspect the design matrix (rows represent time, and\n",
    "columns contain the predictors):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix = fmri_glm.design_matrices_[0]\n",
    "fig, ax1 = plt.subplots(figsize=(6, 8), nrows=1, ncols=1)\n",
    "plot_design_matrix(design_matrix, ax= ax1, rescale= True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column contains the expected reponse profile of regions which are\n",
    "sensitive to the auditory stimulation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(design_matrix['active'])\n",
    "plt.xlabel('scan')\n",
    "plt.title('Expected Auditory Response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting voxels with significant effects\n",
    "-----------------------------------------\n",
    "\n",
    "To access the estimated coefficients (Betas of the GLM model), we\n",
    "created constrasts with a single '1' in each of the columns:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "contrasts = dict([(column, contrast_matrix[i])\n",
    "                  for i, column in enumerate(design_matrix.columns)])\n",
    "\n",
    "\"\"\"\n",
    "contrasts::\n",
    "\n",
    "  {\n",
    "  'active':            array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'active_derivative': array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'constant':          array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
    "  'drift_1':           array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_2':           array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_3':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_4':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_5':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]),\n",
    "  'drift_6':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
    "  'drift_7':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n",
    "  'rest':              array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'rest_derivative':   array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compare the two conditions 'active' and 'rest' by\n",
    "generating the relevant contrast:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_minus_rest =  contrasts['active'] - contrasts['rest']\n",
    "\n",
    "eff_map = fmri_glm.compute_contrast(active_minus_rest,\n",
    "                                    output_type='effect_size')\n",
    "\n",
    "z_map = fmri_glm.compute_contrast(active_minus_rest,\n",
    "                                  output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot thresholded z scores map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(z_map, bg_img=mean_img, threshold=3.0,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Active minus Rest (Z>3)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_img(z_map, bg_img=mean_img, threshold=3., title=\"Active vs. Rest contrast\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ``nibabel.save`` to save the effect and zscore maps to the disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'results'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "nibabel.save(z_map, join('results', 'active_vs_rest_z_map.nii'))\n",
    "nibabel.save(eff_map, join('results', 'active_vs_rest_eff_map.nii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the signal from a voxels\n",
    " --------------------------------\n",
    "\n",
    "We search for the voxel with the larger z-score and plot the signal\n",
    "(warning: double dipping!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the coordinates of the peak\n",
    "\n",
    "\n",
    "values = z_map.get_data()\n",
    "coord_peaks = np.dstack(np.unravel_index(np.argsort(values.ravel()),\n",
    "                                         values.shape))[0, 0, :]\n",
    "coord_mm = apply_affine(z_map.affine, coord_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a masker for the voxel (allowing us to detrend the signal)\n",
    "and extract the time course\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = NiftiSpheresMasker([coord_mm], radius=3,\n",
    "                          detrend=True, standardize=True,\n",
    "                          high_pass=None, low_pass=None, t_r=7.)\n",
    "sig = mask.fit_transform(fmri_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the signal and the theoretical response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frame_times, sig, label='voxel %d %d %d' % tuple(coord_mm))\n",
    "plt.plot(design_matrix['active'], color='red', label='model')\n",
    "plt.xlabel('scan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (3,4));\n",
    "sns.regplot(design_matrix['active'], np.squeeze(sig));\n",
    "plt.xlim([-0.5, 1.5]);\n",
    "plt.xlabel('Predicted response')\n",
    "plt.ylabel('Measured response')\n",
    "#plt.axis('equal')\n",
    "np.corrcoef(np.squeeze(sig),design_matrix['active'] )[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
