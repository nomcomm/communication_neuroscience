{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A introduction tutorial to fMRI decoding\n",
    "==========================================\n",
    "\n",
    "by Nilearn Team\n",
    "\n",
    "added/modified by Ralf Schmaelzle, 2020\n",
    "\n",
    "\n",
    "This tutorial reproduces parts of the classic Haxby 2001 study on a face vs cat discrimination task in a mask of the ventral stream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nilearn import plotting\n",
    "from nilearn.image import mean_img\n",
    "%matplotlib inline\n",
    "\n",
    "from nilearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve and load the fMRI data from the  Haxby study\n",
    "------------------------------------------------------\n",
    "\n",
    "First download the data. The `nilearn.datasets.fetch_haxby` function will download the Haxby dataset if not present on the disk, in the nilearn data directory. It can take a while to download about 310 Mo of data from the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default 2nd subject will be fetched\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "# 'func' is a list of filenames: one for each subject\n",
    "fmri_filename = haxby_dataset.func[0]\n",
    "\n",
    "# print basic information on the dataset\n",
    "print('First subject functional nifti images (4D) are at: %s' %\n",
    "      fmri_filename)  # 4D data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the fmri volume. One way to visualize a fmri volume is using `nilearn.plotting.plot_epi`.\n",
    "We will visualize the previously fecthed fmri data from Haxby dataset.\n",
    "\n",
    "Because fmri data is 4D (it consists of many 3D EPI images), we cannot plot it directly using `nilearn.plotting.plot_epi` (which accepts just 3D input). Here we are using `nilearn.image.mean_img` to \n",
    "extract a single 3D EPI image from the fmri data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_img(mean_img(fmri_filename), threshold=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction: from fMRI volumes to a data matrix\n",
    "\n",
    "These are some really lovely images, but for machine learning we need matrices to work with the actual data. That is, what we want is a matrix that contains voxeldata aligned on a row, and the cases (e.g. trials ..) as rows.\n",
    "\n",
    "e.g. \n",
    "\n",
    "trial_type/label, voxel1, voxel2, volxel3 .... voxelN\n",
    "\n",
    "face, 0.8, 0.3, 0.5,... 0.9\n",
    "\n",
    "house, 0.7, 0.6, 0.4, ...0.6\n",
    "\n",
    "face, 0.4, 0.6, 0.5,... 0.7\n",
    "\n",
    "face, 0.8, 0.3, 0.5,... 0.7\n",
    "\n",
    "...\n",
    "\n",
    "To transform our Nifti images into matrices, we will use the :class:`nilearn.input_data.NiftiMasker` to \n",
    "extract the fMRI data on a mask and convert it to data series. \n",
    "\n",
    "A mask of the Ventral Temporal (VT) cortex coming from the Haxby study is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filename = haxby_dataset.mask_vt[0]\n",
    "\n",
    "# Let's visualize it, using the subject's anatomical image as a background\n",
    "plotting.plot_roi(mask_filename, bg_img=haxby_dataset.anat[0], cmap='Paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the NiftiMasker.\n",
    "\n",
    "We first create a masker, and ask it to normalize the data to improve the\n",
    "decoding. The masker will extract a 2D array ready for machine learning\n",
    "with nilearn:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=mask_filename, standardize=True)\n",
    "fmri_masked = masker.fit_transform(fmri_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable \"fmri_masked\" is a numpy array:\n",
    "\n",
    "Its shape corresponds to the number of time-points times the number of voxels in the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fmri_masked.shape)\n",
    "print(fmri_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "Explain your neighbor what this data is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to think about what just happened is to look at it visually:\n",
    "\n",
    "![](https://nilearn.github.io/_images/masking1.jpg)\n",
    "\n",
    "\n",
    "Essentially, we can think about overlaying a 3D grid on an image. Then,\n",
    "our mask tells us which cubes or \"voxels\" (like 3D pixels) to sample from.\n",
    "Since our Nifti images are 4D files, we can't overlay a single grid --\n",
    "instead, we use a series of 3D grids (one for each volume in the 4D file),\n",
    "so we can get a measurement for each voxel at each timepoint. These are\n",
    "reflected in the shape of the matrix ! You can check this by checking the\n",
    "number of non-negative voxels in our binary brain mask.\n",
    "\n",
    ".. seealso::\n",
    "\tThere are many other strategies in Nilearn `for masking data and for\n",
    "\tgenerating masks <computing_and_applying_mask>`\n",
    "\tI'd encourage you to spend some time exploring the documentation for these.\n",
    "\tWe can also `display this time series `sphx_glr_auto_examples_03_connectivity_plot_sphere_based_connectome.py` to get an intuition of how the\n",
    "\twhole brain signal is changing over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll display the first three voxels by sub-selecting values from the\n",
    "matrix. You can also find more information on how to slice arrays `here\n",
    "<https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#basic-slicing-and-indexing>`_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fmri_masked[5:150, :3])\n",
    "\n",
    "plt.title('Voxel Time Series')\n",
    "plt.xlabel('Scan number')\n",
    "plt.ylabel('Normalized signal')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "Can you find a way to plot some of the fmri_masked-array? \n",
    "\n",
    "Tip (plt.imshow & the notion of slicing) will help you!\n",
    "\n",
    "[Tip2: to insert a cell, either click insert -> cell, or press Esc and then 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the behavioral labels\n",
    "\n",
    "\n",
    "Now that the brain images are converted to a data matrix, we can apply \n",
    "machine-learning to them, for instance to predict the task that the subject \n",
    "was doing. The behavioral labels are stored in a CSV file, separated by\n",
    "spaces.\n",
    "\n",
    "We use pandas to load them in an array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load behavioral information\n",
    "behavioral = pd.read_csv(haxby_dataset.session_target[0], delimiter=' ')\n",
    "print(behavioral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task was a visual-recognition task, and the labels denote the \n",
    "experimental condition: the type of object that was presented to the \n",
    "subject. This is what we are going to try to predict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = behavioral['labels']\n",
    "conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict the analysis to cats and faces\n",
    "........................................\n",
    "\n",
    "As we can see from the targets above, the experiment contains many\n",
    "conditions. As a consequence the data is quite big:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fmri_masked.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all of this data has an interest to us for decoding, so we will keep\n",
    "only fmri signals corresponding to faces or cats. We create a mask of\n",
    "the samples belonging to the condition; this mask is then applied to the\n",
    "fmri data to restrict the classification to the face vs cat discrimination.\n",
    "As a consequence, the input data is much small (i.e. fmri signal is shorter):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_mask = conditions.isin(['face', 'cat'])\n",
    "fmri_masked = fmri_masked[condition_mask]\n",
    "print(fmri_masked.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the same mask to the targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = conditions[condition_mask]\n",
    "print(conditions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "Again, take a moment to reflect and talk this through with your neighbor. Where are we now? What can we do next?\n",
    "you can write a few notes into the comment/markdown cell below (Tip: to change a cell to a comment/markdown  cell, you either press Esc + 'm' or change the type in the pulldown-menu above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding with an SVM\n",
    "---------------------\n",
    "\n",
    "We will now use the `scikit-learn <http://www.scikit-learn.org>`_\n",
    "machine-learning toolbox on the fmri_masked data.\n",
    "\n",
    "As a decoder, we use a Support Vector Classification, with a linear\n",
    "kernel.\n",
    "\n",
    "We first create it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "print(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The svc object is an object that can be fit (or trained) on data with\n",
    "labels, and then predict labels on data without.\n",
    "\n",
    "We first fit it on the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(fmri_masked, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then predict the labels from the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = svc.predict(fmri_masked)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the error rate:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((prediction == conditions).sum() / float(len(conditions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "This error rate is meaningless. \n",
    "\n",
    "Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring prediction scores using cross-validation\n",
    "---------------------------------------------------\n",
    "\n",
    "The proper way to measure error rates or prediction accuracy is via\n",
    "cross-validation: leaving out some data and testing on it.\n",
    "\n",
    "Manually leaving out data\n",
    "..........................\n",
    "\n",
    "Let's leave out the 30 last data points during training, and test the\n",
    "prediction on these 30 last points:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(fmri_masked[:-30], conditions[:-30])\n",
    "\n",
    "prediction = svc.predict(fmri_masked[-30:])\n",
    "print((prediction == conditions[-30:]).sum() / float(len(conditions[-30:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing a KFold loop\n",
    "\n",
    "\n",
    "We can split the data in train and test set repetitively in a `KFold`\n",
    "strategy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5)\n",
    "\n",
    "# The \"cv\" object's split method can now accept data and create a\n",
    "# generator which can yield the splits.\n",
    "for train, test in cv.split(X=fmri_masked):\n",
    "    conditions_masked = conditions.values[train]\n",
    "    svc.fit(fmri_masked[train], conditions_masked)\n",
    "    prediction = svc.predict(fmri_masked[test])\n",
    "    print((prediction == conditions.values[test]).sum()\n",
    "           / float(len(conditions.values[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation with scikit-learn\n",
    "Scikit-learn has tools to perform cross-validation easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score = cross_val_score(svc, fmri_masked, conditions)\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can speed things up to use all the CPUs of our computer with the n_jobs parameter.\n",
    "\n",
    "The best way to do cross-validation is to respect the structure of the experiment, for instance by leaving out full sessions of acquisition.\n",
    "\n",
    "The number of the session is stored in the CSV file giving the behavioral data. We have to apply our session mask, to select only cats and faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_label = behavioral['chunks'][condition_mask]\n",
    "\n",
    "# By default, cross_val_score uses a 3-fold KFold. We can control this by\n",
    "# passing the \"cv\" object, here a 5-fold:\n",
    "cv_score = cross_val_score(svc, fmri_masked, conditions, cv=cv)\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fMRI data is acquired by sessions, and the noise is autocorrelated\n",
    "in a given session. Hence, it is better to predict across sessions when\n",
    "doing cross-validation. To leave a session out, pass it to the groups\n",
    "parameter of cross_val_score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "cv = LeaveOneGroupOut()\n",
    "cv_score = cross_val_score(svc,\n",
    "                           fmri_masked,\n",
    "                           conditions,\n",
    "                           cv=cv,\n",
    "                           groups=session_label,\n",
    "                           )\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the model weights\n",
    "-----------------------------\n",
    "\n",
    "Finally, it may be useful to inspect and display the model weights.\n",
    "\n",
    "Turning the weights into a nifti image\n",
    "\n",
    "We retrieve the SVC discriminating weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_ = svc.coef_\n",
    "print(coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a numpy array with only one coefficient per voxel:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coef_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to turn it back into a Nifti image, in essence, \"inverting\" what the NiftiMasker has done.\n",
    "\n",
    "In other words, we \"map\" the 1-d vector (in this case the svm coefficients for each voxel in our mask) back into the brain-space from which they were taken.\n",
    "\n",
    "For this, we can call inverse_transform on the NiftiMasker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_img = masker.inverse_transform(coef_)\n",
    "print(coef_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the SVM weights\n",
    "\n",
    "coef_img is now a NiftiImage. We can save the coefficients as a nii.gz file:\n",
    "And we can plot the weights, using the subject's anatomical as a background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_img.to_filename('haxby_svc_weights.nii.gz')\n",
    "\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "plot_stat_map(coef_img, bg_img=haxby_dataset.anat[0],\n",
    "              title=\"SVM weights\", display_mode=\"yx\")\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "Inspect the weights. What do you find? \n",
    "\n",
    "Where in the brain are we? What do we know about this region?\n",
    "\n",
    "How do you interpret this result?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
