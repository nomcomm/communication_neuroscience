{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Intro to ISC analysis\n",
    "==============================================================================\n",
    "\n",
    "Author: Ralf Schm√§lzle, 2020\n",
    "\n",
    "In this tutorial, we will learn the ropes of ISC analysis.\n",
    "We will start very simple and I have prepared most of the analysis. In particular, I have downloaded the preprocessed data from a movie-viewing fMRI-study, extracted the neural time-series from a few regions of interest, and stored them (mostly to save time). \n",
    "\n",
    "As usual, just shift-enter-click through the notebook and stop to answer questions as they arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilearn import input_data\n",
    "from nilearn import datasets\n",
    "import sys\n",
    "from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import nilearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell sets up the coordinates from which the data were extracted. If you want, you can verify the coordinates in a brain-viewer of your choice (e.g. Mango, MRICron, BVBrainTutor, or even Neurosynth). The data come from the visual and auditory cortex (i.e. I put holes in the mask at the locations of visual and auditory cortex and extracte the functional data from these regions.). The data were detrended and slightly filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_coords = [(-7, -83, 2),   \n",
    "                   (7, -83, 2),    \n",
    "                   (-62, -30, 12), \n",
    "                   (59, -27, 15)]  \n",
    "\n",
    "networks_labels = [ \n",
    "    'Left V1',  # VS      \n",
    "    'Right V1',                                  \n",
    "    'Left A1',  # AS      \n",
    "    'Right A1',                                  \n",
    "]\n",
    "\n",
    "networks_cols = [ \n",
    "    'cyan',\n",
    "    'cyan',\n",
    "    'purple',\n",
    "    'purple',\n",
    "]\n",
    "\n",
    "n_nodes = len(networks_labels)\n",
    "node_sizes = np.ones(n_nodes)*4\n",
    "                  \n",
    "plotting.plot_connectome(np.zeros((n_nodes,n_nodes)), \n",
    "                         networks_coords, \n",
    "                         node_size  = node_sizes*20, \n",
    "                         node_color = networks_cols, \n",
    "                         title      = \"Example Regions from which timeseries were extracted\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the process of downloading and extracting the data is quite time-consuming, I have already done this. As said, the data were extracted from those 4 regions (2 left and 2 right, auditory/visual cortex), and then stored. We can now load the extracted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjs = 122\n",
    "ts_data = np.load('../data/ts_data.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "    \n",
    "Explore the array named \"ts_data\". \n",
    "\n",
    "What is its shape? (Tip: enter ts_data.shape)\n",
    "\n",
    "What does the shape tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot\n",
    "\n",
    "We'll plot the time-series data that were extracted from the first region and for the first subject (remember: python is \"zero-indexed\", i.e. the first region is the '0-th') . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_to_plot = 0\n",
    "subject_to_plot = 0\n",
    "\n",
    "plt.figure(figsize = (10,3))\n",
    "plt.plot(np.squeeze(ts_data[subject_to_plot, :, region_to_plot].T));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this a bit prettier and more expressive/clearer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,3))\n",
    "plt.plot(np.squeeze(ts_data[subject_to_plot, :, region_to_plot].T));\n",
    "plt.xlabel('Time (in TRs)');\n",
    "plt.ylabel('fMRI signal (z-scored)');\n",
    "plt.title('fMRI-BOLD timeseries during movie-watching: Subject 1, Visual Cortex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot all subjects\n",
    "\n",
    "Remember, the array is organized so that we have\n",
    "ts_data[subjects, timepoints, regions], and if we use the ':' for the subjects-dimension, all subjects will be plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_to_plot = 0\n",
    "plt.figure(figsize = (10,3))\n",
    "plt.plot(np.squeeze(ts_data[:, :, region_to_plot].T));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "    \n",
    "Now, this plot is a bit crowed. \n",
    "\n",
    "Can you edit the code above so that it would plot only - let's say, the first 20 subjects? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average and plot\n",
    "\n",
    "One procedure that helps to see the forest before all the trees is averaging. Averaging together the data from a few subjects will help to beat down the noise and more clearly identify the shared signal. Here, we will average together the first half of the group (the first 61 children) into a new variable called \"first_half\", and we will create a second averaged time-series based on the data of the remaining 61 children. Thus, the two averaged time-series will be completely independent (different children), but they will all have watched the same movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half = np.mean(ts_data[:int(n_subjs/2), :, :], axis = 0)\n",
    "second_half = np.mean(ts_data[int(n_subjs/2):, :, :], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_to_plot = 0\n",
    "\n",
    "plt.figure(figsize = (10,3))\n",
    "plt.plot(first_half[:, region_to_plot],  label = \" First Group (N = 61)\");\n",
    "plt.plot(second_half[:, region_to_plot], label = \" First Group (N = 61)\");\n",
    "\n",
    "plt.ylim([-2.2, 2])\n",
    "plt.xlim([0, 168])\n",
    "\n",
    "plt.xlabel('Time (in TRs)');\n",
    "plt.ylabel('fMRI signal (z-scored)');\n",
    "\n",
    "plt.legend(loc = 4);\n",
    "\n",
    "plt.title('fMRI-BOLD timeseries during movie-watching');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "    \n",
    "What do you see?\n",
    "\n",
    "What does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot as a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "plt.scatter(first_half[:, region_to_plot],\n",
    "            second_half[:, region_to_plot]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "    \n",
    "Estimate the strength of this correlation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ISC\n",
    "\n",
    "Ok. It seems we have something here. \n",
    "\n",
    "Let's see if we can compute an actual number, i.e. an inter-subject correlation (or rather an inter-group correlation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_to_plot = 0 \n",
    "ts1 = first_half[:, region_to_plot]\n",
    "ts2 = second_half[:, region_to_plot]\n",
    "\n",
    "plt.figure(figsize = (10,3))\n",
    "plt.plot(ts1);\n",
    "plt.plot(ts2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen this. I just made it so that now you have vectors (instead of a more complex array). \n",
    "\n",
    "The vector ***ts1*** is the group-averaged time-series from the visual cortex of 61 kids watching a movie.\n",
    "\n",
    "Let's look at the first 20 datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ts2*** is basically the same - just for the 2nd group (subject 61 until 122 -  this time the entire vector of lenght 168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "    \n",
    "Here comes your moment: \n",
    "\n",
    "Please compute the inter-subject correlation (or inter-group correlation): \n",
    "\n",
    "That is, find a way to compare the two vectors!\n",
    "\n",
    "Tip : The formula for this is part of the numpy-package and it goes: np.corrcoef( first_vector , second_vector   ). You can find more about how to use this formula on stackoverflow, the numpy-help... And, if you feel insecure about python at all, you can even copy and past the data from ts1 and ts2 into excel and do it there. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef( ... , ...   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIRST PERSON WITH A CORRECT RESULT WILL GET A PRIZE !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
