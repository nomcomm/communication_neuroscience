{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "BIDS dataset first and second level analysis\n",
    "============================================\n",
    "\n",
    "by Nilearn & Nistats Teams\n",
    "\n",
    "modified/added by Ralf Schmaelzle\n",
    "\n",
    "Full step-by-step example of fitting a GLM to perform a first and second level\n",
    "analysis in a BIDS dataset and visualizing the results. Details about the BIDS\n",
    "standard can be consulted at http://bids.neuroimaging.io/\n",
    "\n",
    "More specifically:\n",
    "\n",
    "1. Download an fMRI BIDS dataset with two language conditions to contrast.\n",
    "2. Extract automatically from the BIDS dataset first level model objects\n",
    "3. Fit a second level model on the fitted first level models. Notice that\n",
    "   in this case the preprocessed bold images were already normalized to the\n",
    "   same MNI space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch example BIDS dataset\n",
    "--------------------------\n",
    "We download an simplified BIDS dataset made available for illustrative\n",
    "purposes. It contains only the necessary\n",
    "information to run a statistical analysis using Nistats. The raw data\n",
    "subject folders only contain bold.json and events.tsv files, while the\n",
    "derivatives folder with preprocessed files contain preproc.nii and\n",
    "confounds.tsv files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nistats.datasets import fetch_language_localizer_demo_dataset\n",
    "data_dir, _ = fetch_language_localizer_demo_dataset()\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain automatically FirstLevelModel objects and fit arguments\n",
    "--------------------------------------------------------------\n",
    "From the dataset directory we obtain automatically FirstLevelModel objects\n",
    "with their subject_id filled from the BIDS dataset. Moreover we obtain\n",
    "for each model a dictionary with run_imgs, events and confounder regressors\n",
    "since in this case a confounds.tsv file is available in the BIDS dataset.\n",
    "To get the first level models we only have to specify the dataset directory\n",
    "and the task_label as specified in the file names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nistats.first_level_model import first_level_models_from_bids\n",
    "task_label = 'languagelocalizer'\n",
    "models, models_run_imgs, models_events, models_confounds = \\\n",
    "    first_level_models_from_bids(\n",
    "        data_dir, task_label,\n",
    "        img_filters=[('desc', 'preproc')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check on fit arguments\n",
    "-----------------------------------\n",
    "Additional checks or information extraction from pre-processed data can\n",
    "be made here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just expect one run img per subject.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print([os.path.basename(run) for run in models_run_imgs[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only confounds stored are regressors obtained from motion correction. As\n",
    "we can verify from the column headers of the confounds table corresponding\n",
    "to the only run_img present\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_confounds[0][0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(models_confounds[2][0].values[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "What is this? What does it mean?\n",
    "\n",
    "\n",
    "Can you modify the code above to check what happened with this subject in the other confounds, and perhaps even in other subjects? If you succeed in doing so, you will learn about the datastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this acquisition the subject read blocks of sentences and\n",
    "consonant strings. So these are our only two conditions in events.\n",
    "We verify there are 12 blocks for each condition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_events[0][0]['trial_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "What again was a block?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First level model estimation\n",
    "----------------------------\n",
    "Now we simply fit each first level model and plot for each subject the\n",
    "contrast that reveals the language network (language - string). Notice that\n",
    "we can define a contrast using the names of the conditions specified in the\n",
    "events dataframe. Sum, substraction and scalar multiplication are allowed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the threshold as the z-variate with an uncorrected p-value of 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "p001_unc = norm.isf(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "What does norm.isf do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare figure for concurrent plot of individual maps (might take a while)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(8, 4.5))\n",
    "model_and_args = zip(models, models_run_imgs, models_events, models_confounds)\n",
    "for midx, (model, imgs, events, confounds) in enumerate(model_and_args):\n",
    "    # fit the GLM\n",
    "    model.fit(imgs, events, confounds)\n",
    "    # compute the contrast of interest\n",
    "    zmap = model.compute_contrast('language-string')\n",
    "    plotting.plot_glass_brain(zmap, colorbar=False, threshold=p001_unc,\n",
    "                              title=('sub-' + model.subject_label),\n",
    "                              axes=axes[int(midx / 5), int(midx % 5)],\n",
    "                              plot_abs=False, display_mode='x')\n",
    "fig.suptitle('subjects z_map language network (unc p<0.001)')\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second level model estimation\n",
    "-----------------------------\n",
    "We just have to provide the list of fitted FirstLevelModel objects to the SecondLevelModel object for estimation. We can do this because all subjects share a similar design matrix (same variables reflected in column names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nistats.second_level_model import SecondLevelModel\n",
    "second_level_input = models\n",
    "second_level_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "How many subjects again? \n",
    "\n",
    "Can you explain to your neighbor what will happen next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the 2nd Level Model\n",
    "\n",
    "Now we fit the model (drumroll)\n",
    "Note that we apply a smoothing of 8mm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_model = SecondLevelModel(smoothing_fwhm=8.0)\n",
    "second_level_model = second_level_model.fit(second_level_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing contrasts at the second level is as simple as at the first level\n",
    "Since we are not providing confounders we are performing an one-sample test\n",
    "at the second level with the images determined by the specified first level\n",
    "contrast.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmap = second_level_model.compute_contrast(\n",
    "    first_level_contrast='language-string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The group level contrast reveals a left lateralized fronto-temporal\n",
    "language network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_img(zmap, colorbar=True, threshold=p001_unc,\n",
    "                          title='Group language network (unc p<0.0001)',\n",
    "                          plot_abs=False, display_mode='x')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:***\n",
    "\n",
    "What do you see? \n",
    "\n",
    "What does this map show us? \n",
    "\n",
    "Can you change the threshold (e.g. to p < 0.0001 uncorrected)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
