{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Univariate analysis of block design, one condition versus rest, single subject\n",
    "==============================================================================\n",
    "\n",
    "Authors: Bertrand Thirion, dohmatob elvis dopgima, Christophe Pallier, 2015--2017\n",
    "\n",
    "\n",
    "\n",
    "In this tutorial, we compare the fMRI signal during periods of auditory stimulation\n",
    "versus periods of rest, using a General Linear Model (GLM). We will\n",
    "use a univariate approach in which independent tests are performed at\n",
    "each single-voxel.\n",
    "\n",
    "The dataset comes from experiment conducted at the FIL by Geriant Rees\n",
    "under the direction of Karl Friston. It is provided by FIL methods\n",
    "group which develops the SPM software.\n",
    "\n",
    "According to SPM documentation, 96 acquisitions were made (RT=7s), in\n",
    "blocks of 6, giving 16 42s blocks. The condition for successive blocks\n",
    "alternated between rest and auditory stimulation, starting with rest.\n",
    "Auditory stimulation was bi-syllabic words presented binaurally at a\n",
    "rate of 60 per minute. The functional data starts at acquisiton 4,\n",
    "image fM00223_004.\n",
    "\n",
    "The whole brain BOLD/EPI images were acquired on a modified 2T Siemens\n",
    "MAGNETOM Vision system. Each acquisition consisted of 64 contiguous\n",
    "slices (64x64x64 3mm x 3mm x 3mm voxels). Acquisition took 6.05s, with\n",
    "the scan to scan repeat time (RT) set arbitrarily to 7s.\n",
    "\n",
    "\n",
    "This analyse described here is performed in the native space, on the\n",
    "original EPI scans without any spatial or temporal preprocessing.\n",
    "(More sensitive results would likely be obtained on the corrected,\n",
    "spatially normalized and smoothed images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will likely give an error, but must be executed anyway\n",
    "#sys.path.append(os.getcwd())\n",
    "#!git clone https://github.com/nistats/nistats.git\n",
    "#os.chdir('./nistats')\n",
    "#!python setup.py install --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the data\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "!pip install nistats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nistats.datasets import fetch_spm_auditory\n",
    "subject_data = fetch_spm_auditory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the filenames of the functional images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first functional image:\n",
    "\n",
    "RalfNote: there will be some ugly red error code. Just re-run the cell again and it should be gone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img\n",
    "plot_img(subject_data.func[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the subject's anatomical image:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anat(subject_data.anat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we concatenate all the 3D EPI image into a single 4D image:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import concat_imgs\n",
    "fmri_img = concat_imgs(subject_data.func)\n",
    "fmri_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we average all the EPI images in order to create a background\n",
    "image that will be used to display the activations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "mean_img = image.mean_img(fmri_img)\n",
    "plot_anat(mean_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the experimental paradigm\n",
    "------------------------------------\n",
    "\n",
    "We must provide a description of the experiment, that is, define the\n",
    "timing of the auditory stimulation and rest periods. According to\n",
    "the documentation of the dataset, there were 16 42s blocks --- in\n",
    "which 6 scans were acquired --- alternating between rest and\n",
    "auditory stimulation, starting with rest. We use standard python\n",
    "functions to create a pandas.DataFrame object that specifies the\n",
    "timings:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tr = 7.\n",
    "slice_time_ref = 0.\n",
    "n_scans = 96\n",
    "epoch_duration = 6 * tr  # duration in seconds\n",
    "conditions = ['rest', 'active'] * 8\n",
    "n_blocks = len(conditions)\n",
    "duration = epoch_duration * np.ones(n_blocks)\n",
    "onset = np.linspace(0, (n_blocks - 1) * epoch_duration, n_blocks)\n",
    "\n",
    "import pandas as pd\n",
    "events = pd.DataFrame({'onset': onset, 'duration': duration, 'trial_type': conditions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``events`` object contains the information for the design:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the GLM analysis\n",
    "---------------------------\n",
    "\n",
    "We need to construct a *design matrix* using the timing information\n",
    "provided by the ``events`` object. The design matrix contains\n",
    "regressors of interest as well as regressors of non-interest\n",
    "modeling temporal drifts:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_times = np.linspace(0, (n_scans - 1) * tr, n_scans)\n",
    "drift_model = 'Cosine'\n",
    "period_cut = 4. * epoch_duration\n",
    "hrf_model = 'glover + derivative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to create a ``FirstLevelModel`` object\n",
    "and fit it to the 4D dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nistats.first_level_model import FirstLevelModel\n",
    "\n",
    "fmri_glm = FirstLevelModel(tr, slice_time_ref, noise_model='ar1',\n",
    "                           standardize=False, hrf_model=hrf_model,\n",
    "                           drift_model=drift_model, period_cut=period_cut)\n",
    "fmri_glm = fmri_glm.fit(fmri_img, events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can inspect the design matrix (rows represent time, and\n",
    "columns contain the predictors):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nistats.reporting import plot_design_matrix\n",
    "design_matrix = fmri_glm.design_matrices_[0]\n",
    "fig, ax1 = plt.subplots(figsize=(6, 8), nrows=1, ncols=1)\n",
    "plot_design_matrix(design_matrix, ax= ax1, rescale= True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column contains the expected reponse profile of regions which are\n",
    "sensitive to the auditory stimulation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(design_matrix['active'])\n",
    "plt.xlabel('scan')\n",
    "plt.title('Expected Auditory Response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting voxels with significant effects\n",
    "-----------------------------------------\n",
    "\n",
    "To access the estimated coefficients (Betas of the GLM model), we\n",
    "created constrasts with a single '1' in each of the columns:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "contrasts = dict([(column, contrast_matrix[i])\n",
    "                  for i, column in enumerate(design_matrix.columns)])\n",
    "\n",
    "\"\"\"\n",
    "contrasts::\n",
    "\n",
    "  {\n",
    "  'active':            array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'active_derivative': array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'constant':          array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
    "  'drift_1':           array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_2':           array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_3':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_4':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]),\n",
    "  'drift_5':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]),\n",
    "  'drift_6':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
    "  'drift_7':           array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]),\n",
    "  'rest':              array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
    "  'rest_derivative':   array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compare the two conditions 'active' and 'rest' by\n",
    "generating the relevant contrast:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_minus_rest =  contrasts['active'] - contrasts['rest']\n",
    "\n",
    "eff_map = fmri_glm.compute_contrast(active_minus_rest,\n",
    "                                    output_type='effect_size')\n",
    "\n",
    "z_map = fmri_glm.compute_contrast(active_minus_rest,\n",
    "                                  output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot thresholded z scores map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(z_map, bg_img=mean_img, threshold=3.0,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Active minus Rest (Z>3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ``nibabel.save`` to save the effect and zscore maps to the disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "outdir = 'results'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "import nibabel\n",
    "from os.path import join\n",
    "nibabel.save(z_map, join('results', 'active_vs_rest_z_map.nii'))\n",
    "nibabel.save(eff_map, join('results', 'active_vs_rest_eff_map.nii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the signal from a voxels\n",
    " --------------------------------\n",
    "\n",
    "We search for the voxel with the larger z-score and plot the signal\n",
    "(warning: double dipping!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the coordinates of the peak\n",
    "\n",
    "from nibabel.affines import apply_affine\n",
    "values = z_map.get_data()\n",
    "coord_peaks = np.dstack(np.unravel_index(np.argsort(values.ravel()),\n",
    "                                         values.shape))[0, 0, :]\n",
    "coord_mm = apply_affine(z_map.affine, coord_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a masker for the voxel (allowing us to detrend the signal)\n",
    "and extract the time course\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "mask = NiftiSpheresMasker([coord_mm], radius=3,\n",
    "                          detrend=True, standardize=True,\n",
    "                          high_pass=None, low_pass=None, t_r=7.)\n",
    "sig = mask.fit_transform(fmri_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the signal and the theoretical response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frame_times, sig, label='voxel %d %d %d' % tuple(coord_mm))\n",
    "plt.plot(design_matrix['active'], color='red', label='model')\n",
    "plt.xlabel('scan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize = (3,4));\n",
    "sns.regplot(design_matrix['active'], np.squeeze(sig));\n",
    "plt.xlim([-0.5, 1.5]);\n",
    "plt.xlabel('Predicted response')\n",
    "plt.ylabel('Measured response')\n",
    "#plt.axis('equal')\n",
    "np.corrcoef(np.squeeze(sig),design_matrix['active'] )[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
